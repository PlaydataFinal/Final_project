{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# url 주소 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [2:09:00<00:00,  7.71s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 s_tit  \\\n",
      "0                            나미송 머무는 곳   \n",
      "1                           해비치호텔앤드리조트   \n",
      "2                               신라호텔제주   \n",
      "3                              롯데호텔 제주   \n",
      "4     휴양펜션 스위스마을 Swiss Village Pension   \n",
      "...                                ...   \n",
      "999                              훼밀리민박   \n",
      "1000                            휴마루리조트   \n",
      "1001                              휴일기록   \n",
      "1002                             히든스테이   \n",
      "1003                            힐링캠프펜션   \n",
      "\n",
      "                                             link1_href  \n",
      "0     https://www.visitjeju.net/kr/detail/view?conte...  \n",
      "1     https://www.visitjeju.net/kr/detail/view?conte...  \n",
      "2     https://www.visitjeju.net/kr/detail/view?conte...  \n",
      "3     https://www.visitjeju.net/kr/detail/view?conte...  \n",
      "4     https://www.visitjeju.net/kr/detail/view?conte...  \n",
      "...                                                 ...  \n",
      "999   https://www.visitjeju.net/kr/detail/view?conte...  \n",
      "1000  https://www.visitjeju.net/kr/detail/view?conte...  \n",
      "1001  https://www.visitjeju.net/kr/detail/view?conte...  \n",
      "1002  https://www.visitjeju.net/kr/detail/view?conte...  \n",
      "1003  https://www.visitjeju.net/kr/detail/view?conte...  \n",
      "\n",
      "[1004 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# driver_path = '/path/to/chromedriver'\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.visitjeju.net/kr/detail/list?menuId=DOM_000001707000000000&cate1cd=cate0000000004#p1&pageSize=1004&sortListType=reviewcnt&viewType=map&isShowBtag&tag\"\n",
    "driver.get(url)\n",
    "# 페이지 로드를 기다립니다.\n",
    "driver.implicitly_wait(10)\n",
    "s_tit_list = []\n",
    "href_list = []\n",
    "# 첫 번째 페이지에서 각 관광지 정보를 클릭합니다.\n",
    "for i in tqdm(range(1, 1005)):  # 숙박업소 수\n",
    "    try:\n",
    "        element = driver.find_element(By.CSS_SELECTOR, f\"#map_outline > div > ul > li:nth-child({i}) > dl > dt > a > p.s_tit\")\n",
    "        s_tit = element.text\n",
    "        # element가 화면 내에 보이도록 스크롤\n",
    "        #driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "        # element를 클릭하기 전에 충분히 대기\n",
    "        ActionChains(driver).move_to_element(element).perform()\n",
    "        time.sleep(2)\n",
    "        # element 클릭\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "        # 'link1' 클래스를 가진 모든 웹 요소를 찾습니다.\n",
    "        link1_elements = driver.find_elements(By.CLASS_NAME, 'link1')\n",
    "        # 각 웹 요소의 href 값을 추출합니다.\n",
    "        for link1_element in link1_elements:\n",
    "            href = link1_element.get_attribute('href')\n",
    "            s_tit_list.append(s_tit)\n",
    "            href_list.append(href)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred at {i}th place: {e}\")\n",
    "# WebDriver 종료\n",
    "driver.quit()\n",
    "# href 값의 리스트를 데이터프레임으로 변환\n",
    "df5 = pd.DataFrame({'s_tit': s_tit_list, 'link1_href': href_list})\n",
    "# 데이터프레임 출력\n",
    "print(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame을 CSV 파일로 저장\n",
    "df5.to_csv('sleep_url.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세부정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('food_url.csv')\n",
    "# 칼럼명 변경\n",
    "df = df.rename(columns={'s_tit': 'name', 'link1_href': 'url'})\n",
    "url = df['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       https://www.visitjeju.net/kr/detail/view?conte...\n",
       "1       https://www.visitjeju.net/kr/detail/view?conte...\n",
       "2       https://www.visitjeju.net/kr/detail/view?conte...\n",
       "3       https://www.visitjeju.net/kr/detail/view?conte...\n",
       "4       https://www.visitjeju.net/kr/detail/view?conte...\n",
       "                              ...                        \n",
       "1980    https://www.visitjeju.net/kr/detail/view?conte...\n",
       "1981    https://www.visitjeju.net/kr/detail/view?conte...\n",
       "1982    https://www.visitjeju.net/kr/detail/view?conte...\n",
       "1983    https://www.visitjeju.net/kr/detail/view?conte...\n",
       "1984    https://www.visitjeju.net/kr/detail/view?conte...\n",
       "Name: url, Length: 1985, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver_manager) (2.31.0)\n",
      "Collecting python-dotenv (from webdriver_manager)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\playdata\\appdata\\roaming\\python\\python312\\site-packages (from webdriver_manager) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver_manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver_manager) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver_manager) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver_manager) (2024.2.2)\n",
      "Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver_manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver_manager-4.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [33:26<00:00,  4.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib3.util.retry import Retry\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "# 크롬 웹드라이버 불러오기\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument(\"--single-process\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "#path='/home/sadf/chromedriver'\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "#url = pd.read_csv('url.csv') # 여기에 실제 URL 목록을 넣어주세요.\n",
    "# URL 목록\n",
    "url_list =df['url']  \n",
    "\n",
    "# 데이터를 담을 빈 리스트 생성\n",
    "data_list = []\n",
    "\n",
    "# URL 목록을 기반으로 반복문 실행\n",
    "for url in tqdm(url_list[0:500]):\n",
    "\n",
    "    # 각 URL에 접근하여 데이터 수집\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    #2차 크롤링을 위한 bs4 셋팅\n",
    "    session = requests.Session()\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"}\n",
    "\n",
    "    retries = Retry(total=5,\n",
    "                    backoff_factor=0.1,\n",
    "                    status_forcelist=[ 500, 502, 503, 504 ])\n",
    "\n",
    "    session.mount('http://', HTTPAdapter(max_retries=retries))  \n",
    "\n",
    "    html = driver.page_source\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    #지명\n",
    "    name = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.sub_info_title > h3')\n",
    "    #별점\n",
    "    score = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.score_area_l > p')\n",
    "\n",
    "    #태그\n",
    "    tag = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.tag_area')\n",
    "\n",
    "    #주소\n",
    "    address = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.basic_information > div:nth-child(2) > p.info_sub_cont')\n",
    "\n",
    "    #전화번호\n",
    "    tel = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.basic_information > div:nth-child(3) > p.info_sub_cont')\n",
    "\n",
    "    # 좋아요 개수\n",
    "    like_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(1) > button > p.appraisal_cnt')\n",
    "\n",
    "    #찜하기 개수\n",
    "    Steaming_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(2) > button > p.appraisal_cnt')\n",
    "\n",
    "    #리뷰 개수\n",
    "    review_count =bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(3) > p.appraisal_cnt')\n",
    "\n",
    "\n",
    "    #방문했어요 수\n",
    "    visit_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(5) > p.appraisal_cnt')\n",
    "\n",
    "    #조회 수\n",
    "    hits = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(6) > p.appraisal_cnt')\n",
    "\n",
    "    #sns 공유 수\n",
    "    sns_share_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(7) > p.appraisal_cnt')\n",
    "\n",
    "\n",
    "    detail_box_elements = bs.select_one('.add2020_detail_box_in')\n",
    "    detail_box_side_elements = bs.select_one('.add2020_detail_side_info')\n",
    "    #대표 사진 url\n",
    "    # CSS 선택자를 사용하여 원하는 요소 찾기\n",
    "    selected_element = bs.select_one('div.sub_visual_wrap')\n",
    "\n",
    "    # image_url을 칼럼으로 만들어주기\n",
    "    if selected_element:\n",
    "        background_style = selected_element.get('style', '')\n",
    "        if 'background' in background_style and 'url' in background_style:\n",
    "            image_url = background_style.split(\"url(\")[-1].split(\")\")[0].replace('&quot;', '')\n",
    "    # 데이터를 딕셔너리에 저장 (비어 있는 경우 빈 문자열로 처리)\n",
    "    data = {\n",
    "        'Name': name.text.strip() if name else \"\",\n",
    "        'Score': score.text.strip() if score else \"\",\n",
    "        'Tag': tag.text.strip() if tag else \"\",\n",
    "        'Address': address.text.strip() if address else \"\",\n",
    "        'Tel': tel.text.strip() if tel else \"\",\n",
    "        'Like Count': like_count.text.strip() if like_count else \"\",\n",
    "        'Steaming Count': Steaming_count.text.strip() if Steaming_count else \"\",\n",
    "        'Review Count': review_count.text.strip() if review_count else \"\",\n",
    "        'Visit Count': visit_count.text.strip() if visit_count else \"\",\n",
    "        'Hits': hits.text.strip() if hits else \"\",\n",
    "        'SNS Share Count': sns_share_count.text.strip() if sns_share_count else \"\",\n",
    "        'detail_box_elements': detail_box_elements.text.strip() if detail_box_elements else \"\",\n",
    "        'detail_box_side_elements': detail_box_side_elements.text.strip() if detail_box_side_elements else \"\",\n",
    "        'Image URL': image_url\n",
    "    }\n",
    "    # 데이터 리스트에 딕셔너리 추가\n",
    "    data_list.append(data)\n",
    "    time.sleep(2)\n",
    "# 데이터 프레임 생성\n",
    "df1 = pd.DataFrame(data_list)\n",
    "\n",
    "# 데이터 csv 저장\n",
    "df1.to_csv('foodinfo1.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [32:50<00:00,  3.94s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib3.util.retry import Retry\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "# 크롬 웹드라이버 불러오기\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument(\"--single-process\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "#path='/home/sadf/chromedriver'\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "#url = pd.read_csv('url.csv') # 여기에 실제 URL 목록을 넣어주세요.\n",
    "# URL 목록\n",
    "url_list =df['url']  \n",
    "\n",
    "# 데이터를 담을 빈 리스트 생성\n",
    "data_list = []\n",
    "\n",
    "# URL 목록을 기반으로 반복문 실행\n",
    "for url in tqdm(url_list[500:1000]):\n",
    "\n",
    "    # 각 URL에 접근하여 데이터 수집\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    #2차 크롤링을 위한 bs4 셋팅\n",
    "    session = requests.Session()\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"}\n",
    "\n",
    "    retries = Retry(total=5,\n",
    "                    backoff_factor=0.1,\n",
    "                    status_forcelist=[ 500, 502, 503, 504 ])\n",
    "\n",
    "    session.mount('http://', HTTPAdapter(max_retries=retries))  \n",
    "\n",
    "    html = driver.page_source\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    #지명\n",
    "    name = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.sub_info_title > h3')\n",
    "    #별점\n",
    "    score = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.score_area_l > p')\n",
    "\n",
    "    #태그\n",
    "    tag = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.tag_area')\n",
    "\n",
    "    #주소\n",
    "    address = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.basic_information > div:nth-child(2) > p.info_sub_cont')\n",
    "\n",
    "    #전화번호\n",
    "    tel = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.basic_information > div:nth-child(3) > p.info_sub_cont')\n",
    "\n",
    "    # 좋아요 개수\n",
    "    like_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(1) > button > p.appraisal_cnt')\n",
    "\n",
    "    #찜하기 개수\n",
    "    Steaming_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(2) > button > p.appraisal_cnt')\n",
    "\n",
    "    #리뷰 개수\n",
    "    review_count =bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(3) > p.appraisal_cnt')\n",
    "\n",
    "\n",
    "    #방문했어요 수\n",
    "    visit_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(5) > p.appraisal_cnt')\n",
    "\n",
    "    #조회 수\n",
    "    hits = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(6) > p.appraisal_cnt')\n",
    "\n",
    "    #sns 공유 수\n",
    "    sns_share_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(7) > p.appraisal_cnt')\n",
    "\n",
    "\n",
    "    detail_box_elements = bs.select_one('.add2020_detail_box_in')\n",
    "    detail_box_side_elements = bs.select_one('.add2020_detail_side_info')\n",
    "    #대표 사진 url\n",
    "    # CSS 선택자를 사용하여 원하는 요소 찾기\n",
    "    selected_element = bs.select_one('div.sub_visual_wrap')\n",
    "\n",
    "    # image_url을 칼럼으로 만들어주기\n",
    "    if selected_element:\n",
    "        background_style = selected_element.get('style', '')\n",
    "        if 'background' in background_style and 'url' in background_style:\n",
    "            image_url = background_style.split(\"url(\")[-1].split(\")\")[0].replace('&quot;', '')\n",
    "    # 데이터를 딕셔너리에 저장 (비어 있는 경우 빈 문자열로 처리)\n",
    "    data = {\n",
    "        'Name': name.text.strip() if name else \"\",\n",
    "        'Score': score.text.strip() if score else \"\",\n",
    "        'Tag': tag.text.strip() if tag else \"\",\n",
    "        'Address': address.text.strip() if address else \"\",\n",
    "        'Tel': tel.text.strip() if tel else \"\",\n",
    "        'Like Count': like_count.text.strip() if like_count else \"\",\n",
    "        'Steaming Count': Steaming_count.text.strip() if Steaming_count else \"\",\n",
    "        'Review Count': review_count.text.strip() if review_count else \"\",\n",
    "        'Visit Count': visit_count.text.strip() if visit_count else \"\",\n",
    "        'Hits': hits.text.strip() if hits else \"\",\n",
    "        'SNS Share Count': sns_share_count.text.strip() if sns_share_count else \"\",\n",
    "        'detail_box_elements': detail_box_elements.text.strip() if detail_box_elements else \"\",\n",
    "        'detail_box_side_elements': detail_box_side_elements.text.strip() if detail_box_side_elements else \"\",\n",
    "        'Image URL': image_url\n",
    "    }\n",
    "    # 데이터 리스트에 딕셔너리 추가\n",
    "    data_list.append(data)\n",
    "    time.sleep(2)\n",
    "# 데이터 프레임 생성\n",
    "df2 = pd.DataFrame(data_list)\n",
    "\n",
    "# 데이터 csv 저장\n",
    "df2.to_csv('foodinfo2.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 985/985 [1:04:36<00:00,  3.94s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib3.util.retry import Retry\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "# 크롬 웹드라이버 불러오기\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument(\"--single-process\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "#path='/home/sadf/chromedriver'\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "#url = pd.read_csv('url.csv') # 여기에 실제 URL 목록을 넣어주세요.\n",
    "# URL 목록\n",
    "url_list =df['url']  \n",
    "\n",
    "# 데이터를 담을 빈 리스트 생성\n",
    "data_list = []\n",
    "\n",
    "# URL 목록을 기반으로 반복문 실행\n",
    "for url in tqdm(url_list[1000:]):\n",
    "\n",
    "    # 각 URL에 접근하여 데이터 수집\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    #2차 크롤링을 위한 bs4 셋팅\n",
    "    session = requests.Session()\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"}\n",
    "\n",
    "    retries = Retry(total=5,\n",
    "                    backoff_factor=0.1,\n",
    "                    status_forcelist=[ 500, 502, 503, 504 ])\n",
    "\n",
    "    session.mount('http://', HTTPAdapter(max_retries=retries))  \n",
    "\n",
    "    html = driver.page_source\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    #지명\n",
    "    name = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.sub_info_title > h3')\n",
    "    #별점\n",
    "    score = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.score_area_l > p')\n",
    "\n",
    "    #태그\n",
    "    tag = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.tag_area')\n",
    "\n",
    "    #주소\n",
    "    address = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.basic_information > div:nth-child(2) > p.info_sub_cont')\n",
    "\n",
    "    #전화번호\n",
    "    tel = bs.select_one('#content > div.cont.detail_page.detail_style > div.sub_visual_wrap > div.inner_wrap > div.sub_info_area > div.basic_information > div:nth-child(3) > p.info_sub_cont')\n",
    "\n",
    "    # 좋아요 개수\n",
    "    like_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(1) > button > p.appraisal_cnt')\n",
    "\n",
    "    #찜하기 개수\n",
    "    Steaming_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(2) > button > p.appraisal_cnt')\n",
    "\n",
    "    #리뷰 개수\n",
    "    review_count =bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(3) > p.appraisal_cnt')\n",
    "\n",
    "\n",
    "    #방문했어요 수\n",
    "    visit_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(5) > p.appraisal_cnt')\n",
    "\n",
    "    #조회 수\n",
    "    hits = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(6) > p.appraisal_cnt')\n",
    "\n",
    "    #sns 공유 수\n",
    "    sns_share_count = bs.select_one('#content > div.cont.detail_page.detail_style > div.cont_wrap.sub_visual > ul > li:nth-child(7) > p.appraisal_cnt')\n",
    "\n",
    "\n",
    "    detail_box_elements = bs.select_one('.add2020_detail_box_in')\n",
    "    detail_box_side_elements = bs.select_one('.add2020_detail_side_info')\n",
    "    #대표 사진 url\n",
    "    # CSS 선택자를 사용하여 원하는 요소 찾기\n",
    "    selected_element = bs.select_one('div.sub_visual_wrap')\n",
    "\n",
    "    # image_url을 칼럼으로 만들어주기\n",
    "    if selected_element:\n",
    "        background_style = selected_element.get('style', '')\n",
    "        if 'background' in background_style and 'url' in background_style:\n",
    "            image_url = background_style.split(\"url(\")[-1].split(\")\")[0].replace('&quot;', '')\n",
    "    # 데이터를 딕셔너리에 저장 (비어 있는 경우 빈 문자열로 처리)\n",
    "    data = {\n",
    "        'Name': name.text.strip() if name else \"\",\n",
    "        'Score': score.text.strip() if score else \"\",\n",
    "        'Tag': tag.text.strip() if tag else \"\",\n",
    "        'Address': address.text.strip() if address else \"\",\n",
    "        'Tel': tel.text.strip() if tel else \"\",\n",
    "        'Like Count': like_count.text.strip() if like_count else \"\",\n",
    "        'Steaming Count': Steaming_count.text.strip() if Steaming_count else \"\",\n",
    "        'Review Count': review_count.text.strip() if review_count else \"\",\n",
    "        'Visit Count': visit_count.text.strip() if visit_count else \"\",\n",
    "        'Hits': hits.text.strip() if hits else \"\",\n",
    "        'SNS Share Count': sns_share_count.text.strip() if sns_share_count else \"\",\n",
    "        'detail_box_elements': detail_box_elements.text.strip() if detail_box_elements else \"\",\n",
    "        'detail_box_side_elements': detail_box_side_elements.text.strip() if detail_box_side_elements else \"\",\n",
    "        'Image URL': image_url\n",
    "    }\n",
    "    # 데이터 리스트에 딕셔너리 추가\n",
    "    data_list.append(data)\n",
    "    time.sleep(2)\n",
    "# 데이터 프레임 생성\n",
    "df3 = pd.DataFrame(data_list)\n",
    "\n",
    "# 데이터 csv 저장\n",
    "df3.to_csv('foodinfo3.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('sleepinfo2.csv')\n",
    "df3 = pd.read_csv('sleepinfo1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df1, df2, df3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('food_all_list.csv',index= False, encoding= 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
